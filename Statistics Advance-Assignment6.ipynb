{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "235e2f80-5b3a-4c11-84f4-34336215c5da",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results.\n",
    "\n",
    "Answer(Q1):\n",
    "\n",
    "Analysis of Variance (ANOVA) is a statistical method used to compare the means of three or more groups and determine if there are any significant differences between them. To ensure the validity of the ANOVA results, several assumptions need to be met. Violations of these assumptions can impact the accuracy and reliability of the analysis. The main assumptions for ANOVA are:\n",
    "\n",
    "1. **Independence of Observations**: The observations within each group must be independent of each other. This means that the data points should not be influenced by or dependent on each other.\n",
    "\n",
    "2. **Normality**: The dependent variable (the outcome being measured) should follow a normal distribution in each group. This is important because ANOVA is sensitive to departures from normality, especially with small sample sizes.\n",
    "\n",
    "3. **Homogeneity of Variance (Homoscedasticity)**: The variance of the dependent variable should be approximately equal across all groups. Homogeneity of variance ensures that the groups have similar variability, which is a key assumption for ANOVA.\n",
    "\n",
    "4. **Equal Sample Sizes (for one-way ANOVA)**: For one-way ANOVA (comparing means across multiple groups), it is preferable to have equal sample sizes in each group. Unequal sample sizes can lead to less statistical power and affect the validity of the results.\n",
    "\n",
    "5. **No Outliers**: Outliers are extreme data points that significantly differ from the rest of the data. Outliers can skew the results and affect the assumptions of normality and homogeneity of variance.\n",
    "\n",
    "Examples of violations and their impact on ANOVA:\n",
    "\n",
    "1. **Non-Independence**: If observations within groups are not independent (e.g., repeated measures on the same subjects), it violates the independence assumption. This can lead to pseudoreplication and an inflated Type I error rate, making the ANOVA results unreliable.\n",
    "\n",
    "2. **Non-Normality**: If the dependent variable's distribution in any group deviates significantly from normality, ANOVA results may be inaccurate. For example, if the data is heavily skewed or has heavy tails, it can lead to incorrect conclusions.\n",
    "\n",
    "3. **Heteroscedasticity**: Violation of homogeneity of variance occurs when the variability of the dependent variable differs significantly across groups. This can result in inflated or deflated Type I error rates and may lead to incorrect identification of significant differences between groups.\n",
    "\n",
    "4. **Unequal Sample Sizes**: In one-way ANOVA, having unequal sample sizes can affect the overall F-test's power and decrease the sensitivity to detect true group differences.\n",
    "\n",
    "5. **Presence of Outliers**: Outliers can distort the group means and standard deviations, affecting the validity of ANOVA results, especially if the sample size is small.\n",
    "\n",
    "When these assumptions are violated, researchers may need to consider alternative methods or transformations to address the issues. For example, non-parametric tests like the Kruskal-Wallis test can be used when the normality assumption is violated, and Welch's ANOVA can handle unequal variances and sample sizes. It's essential for researchers to assess these assumptions before conducting ANOVA and to interpret the results cautiously, especially when the assumptions are not met."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268089ee-31fe-4e81-85ae-05adbc54fb85",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?\n",
    "\n",
    "Answer(Q2):\n",
    "\n",
    "\n",
    "The three types of ANOVA are:\n",
    "\n",
    "1. **One-Way ANOVA**: One-Way ANOVA is used when you have one categorical independent variable (also called a factor) and one continuous dependent variable. The independent variable divides the data into three or more groups, and the goal is to determine if there are any significant differences in the means of the dependent variable across these groups. It is suitable for situations where you want to compare the means of multiple groups, such as testing the effect of different doses of a drug on blood pressure (with dose levels as the groups) or comparing the average scores of students from three different schools.\n",
    "\n",
    "2. **Two-Way ANOVA**: Two-Way ANOVA is an extension of the one-way ANOVA and is used when you have two categorical independent variables (factors) and one continuous dependent variable. It allows you to investigate the main effects of each factor and their interaction effect on the dependent variable. This is useful when you want to examine how two independent variables, either separately or combined, affect the outcome. For instance, in a study analyzing the impact of both gender and education level on income, you would use a two-way ANOVA.\n",
    "\n",
    "3. **Repeated Measures ANOVA**: Repeated Measures ANOVA is used when you have a single group of participants who are measured under different conditions or at multiple time points. This type of ANOVA is appropriate when you want to investigate the effects of a treatment or intervention within the same group over time or under different conditions. For example, a study examining the performance of individuals on a memory task before intervention, immediately after intervention, and one week after intervention would use repeated measures ANOVA.\n",
    "\n",
    "Each type of ANOVA serves different purposes based on the design of the study and the nature of the data. It's essential to choose the appropriate type of ANOVA based on the research question and the structure of the independent and dependent variables. Additionally, when using ANOVA, it's crucial to ensure that the assumptions mentioned in the previous response (independence, normality, homogeneity of variance, etc.) are met for valid and reliable results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6693ed98-8ed4-4826-9a76-38434cad63b3",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\n",
    "\n",
    "Answer(Q3):\n",
    "\n",
    "The partitioning of variance in ANOVA refers to the division of the total variance in the data into different components that can be attributed to specific sources of variability. Understanding this concept is crucial because it allows researchers to identify and quantify the sources of variation in the data, which helps in drawing meaningful conclusions about the factors influencing the dependent variable.\n",
    "\n",
    "In ANOVA, the total variance in the data is decomposed into three main components:\n",
    "\n",
    "1. **Between-Groups Variance**: This component of variance represents the variability between the group means. It measures the differences among the group means in a one-way ANOVA or the combined effects of two or more independent variables in a two-way ANOVA. The between-groups variance reflects the influence of the independent variables on the dependent variable and is the variance that ANOVA aims to test for significance.\n",
    "\n",
    "2. **Within-Groups Variance**: Also known as the error variance or residual variance, this component accounts for the variability within each group or condition. It represents the individual differences and random fluctuations that are not explained by the independent variables. In other words, it quantifies the variability that is due to chance or measurement error.\n",
    "\n",
    "3. **Total Variance**: The total variance is the overall variability in the data, and it is the sum of both between-groups variance and within-groups variance. Mathematically, it is represented as:\n",
    "\n",
    "   Total Variance = Between-Groups Variance + Within-Groups Variance\n",
    "\n",
    "Understanding the partitioning of variance is essential for several reasons:\n",
    "\n",
    "1. **Significance Testing**: ANOVA tests whether the differences between group means (between-groups variance) are significant compared to the variability within each group (within-groups variance). By understanding the partitioning, researchers can assess the statistical significance of the effects of the independent variables.\n",
    "\n",
    "2. **Interpretation of Results**: Knowing the contributions of between-groups and within-groups variance helps researchers interpret the practical significance of the findings. If the between-groups variance is substantial compared to the within-groups variance, it suggests that the independent variables have a meaningful impact on the dependent variable.\n",
    "\n",
    "3. **Effect Size Calculation**: The partitioning of variance is used to calculate effect size measures, such as eta-squared (η²) or partial eta-squared (η²p). These effect sizes quantify the proportion of variance in the dependent variable that can be attributed to the independent variables, providing a measure of practical significance.\n",
    "\n",
    "4. **Study Design and Power Analysis**: Understanding the partitioning of variance can inform researchers in designing future studies and conducting power analyses to estimate the required sample size for detecting significant effects.\n",
    "\n",
    "By understanding how the variance in the data is divided among different sources, researchers can make informed decisions, draw accurate conclusions, and gain valuable insights into the factors that influence the dependent variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd050e0-848e-4ba7-9d97-efe55fc6b647",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?\n",
    "\n",
    "Answer(Q4):\n",
    "\n",
    "To calculate the Total Sum of Squares (SST), Explained Sum of Squares (SSE), and Residual Sum of Squares (SSR) in a one-way ANOVA using Python, you can use libraries such as NumPy and SciPy. Here's a step-by-step guide:\n",
    "\n",
    "Suppose you have a dataset with a dependent variable `y` and a categorical independent variable (factor) `group`. We'll assume that `y` is a NumPy array or a Pandas Series, and `group` is a NumPy array or a Pandas Categorical Series representing the group labels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c398ce1-6749-4b64-b71b-f0fb868c39fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 588.5\n",
      "Explained Sum of Squares (SSE): 136.84027777777771\n",
      "Residual Sum of Squares (SSR): 451.6597222222223\n",
      "F-statistic: 12.923255813953494\n",
      "p-value: 0.0044681809585867625\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Sample data\n",
    "y = np.array([30, 35, 32, 40, 38, 45, 42, 48, 50, 55])\n",
    "group = np.array(['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C', 'C'])\n",
    "\n",
    "# Calculate the group means\n",
    "group_means = y.groupby(group).mean() if isinstance(y, pd.Series) else np.array([y[group == g].mean() for g in np.unique(group)])\n",
    "\n",
    "# Calculate the overall mean\n",
    "overall_mean = y.mean()\n",
    "\n",
    "# Calculate Total Sum of Squares (SST)\n",
    "SST = np.sum((y - overall_mean) ** 2)\n",
    "\n",
    "# Calculate Explained Sum of Squares (SSE)\n",
    "SSE = np.sum((group_means - overall_mean) ** 2)\n",
    "\n",
    "# Calculate Residual Sum of Squares (SSR)\n",
    "SSR = SST - SSE\n",
    "\n",
    "# Print the results\n",
    "print(\"Total Sum of Squares (SST):\", SST)\n",
    "print(\"Explained Sum of Squares (SSE):\", SSE)\n",
    "print(\"Residual Sum of Squares (SSR):\", SSR)\n",
    "\n",
    "# Perform one-way ANOVA to get the F-statistic and p-value\n",
    "f_statistic, p_value = f_oneway(*[y[group == g] for g in np.unique(group)])\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5701ba-0f7f-4e68-a9a7-857b6c8e6bb9",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?\n",
    "\n",
    "Answer(Q5):\n",
    "\n",
    "In a two-way ANOVA, you can calculate the main effects and interaction effects using Python by fitting a two-way ANOVA model and analyzing the model's parameters. One way to perform this analysis is by using the `statsmodels` library in Python. Here's a step-by-step guide on how to calculate main effects and interaction effects:\n",
    "\n",
    "Suppose you have a dataset with a dependent variable `y`, and two categorical independent variables (factors) `factor_A` and `factor_B`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2524b307-f135-43e7-8e58-293852d2de41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       sum_sq   df         F    PR(>F)\n",
      "factor_A            12.166667  2.0  0.087635  0.917246\n",
      "factor_B           102.083333  1.0  1.470588  0.270829\n",
      "factor_A:factor_B    2.166667  2.0  0.015606  0.984555\n",
      "Residual           416.500000  6.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'y': [10, 15, 20, 25, 12, 18, 22, 27, 8, 16, 24, 30],\n",
    "    'factor_A': ['A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'C', 'C', 'C', 'C'],\n",
    "    'factor_B': ['X', 'Y', 'X', 'Y', 'X', 'Y', 'X', 'Y', 'X', 'Y', 'X', 'Y']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('y ~ factor_A + factor_B + factor_A:factor_B', data=df).fit()\n",
    "\n",
    "# Get the ANOVA table\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(anova_table)\n",
    "\n",
    "\n",
    "# The ANOVA table contains the information about the main effects of `factor_A` and `factor_B`, as well as the interaction effect between\n",
    "# the two factors. The key columns in the table are `sum_sq` (sum of squares), `df` (degrees of freedom), `F` (F-statistic), and `PR(>F)` (p-value).\n",
    "\n",
    "# - The main effect of `factor_A` is significant if the corresponding p-value (PR(>F)) is below a chosen significance level (e.g., 0.05).\n",
    "# - The main effect of `factor_B` is significant if the corresponding p-value is below the significance level.\n",
    "# - The interaction effect between `factor_A` and `factor_B` is significant if its p-value is below the significance level.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efb847c-f2b8-46b9-9bf4-5d4950275c81",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?\n",
    "\n",
    "Answer(Q6):\n",
    "\n",
    "\n",
    "In a one-way ANOVA, the F-statistic is used to test whether there are significant differences between the means of three or more groups. The p-value associated with the F-statistic indicates the probability of obtaining the observed results (or more extreme results) if there were no true differences between the group means.\n",
    "\n",
    "In your scenario, the F-statistic is 5.23, and the p-value is 0.02. To interpret these results:\n",
    "\n",
    "1. **Significance of Differences**: The p-value (0.02) is less than the typical significance level of 0.05 (5%). This indicates that there is strong evidence to reject the null hypothesis that there are no differences between the group means. In other words, the results suggest that the means of at least some of the groups are statistically different from each other.\n",
    "\n",
    "2. **Interpretation of F-statistic**: The F-statistic (5.23) represents the ratio of variance between the groups to the variance within the groups. A larger F-statistic indicates a greater difference between the group means relative to the variability within the groups. In this case, the F-statistic of 5.23 suggests that there is substantial variability between the groups compared to the variation within each group.\n",
    "\n",
    "3. **Practical Significance**: While the one-way ANOVA indicates that there are statistically significant differences between the groups, it's also important to consider the practical significance of these differences. The effect size measures (e.g., eta-squared) can be used to quantify the proportion of variance in the dependent variable explained by the group differences, providing a measure of practical significance.\n",
    "\n",
    "4. **Post-hoc Tests**: If your one-way ANOVA results are significant, it may be appropriate to conduct post-hoc tests (e.g., Tukey's HSD, Bonferroni correction) to identify which specific groups differ significantly from each other. These tests help you pinpoint the specific group(s) responsible for the significant differences observed in the overall ANOVA.\n",
    "\n",
    "In conclusion, based on the F-statistic of 5.23 and the p-value of 0.02, you can infer that there are statistically significant differences between the group means. However, it is essential to consider effect sizes and conduct post-hoc tests to further investigate and interpret the specific nature of these differences among the groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716cd1c5-3e59-40f2-9320-f9c50a5b374a",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?\n",
    "\n",
    "\n",
    "Answer(Q7):\n",
    "\n",
    "Handling missing data in a repeated measures ANOVA is crucial to ensure the validity and accuracy of the results. There are several methods to deal with missing data, each with its advantages and potential consequences. Here are some common approaches:\n",
    "\n",
    "1. **Complete Case Analysis (Listwise Deletion)**: This method involves excluding any participants or cases with missing data on any of the variables used in the analysis. While this approach is straightforward, it can lead to a reduction in sample size, potentially reducing statistical power and generalizability. Additionally, if the data are not missing completely at random (MCAR), this method may introduce bias into the results.\n",
    "\n",
    "2. **Mean Imputation**: Missing values are replaced with the mean of the observed values for the respective variable. While this method maintains the sample size, it may artificially reduce variability and lead to underestimation of standard errors and inflated Type I error rates. Mean imputation assumes that the missing values have the same mean as the observed values, which is not always valid.\n",
    "\n",
    "3. **Last Observation Carried Forward (LOCF)**: Missing values are imputed using the last observed value for that participant. This method assumes that the participant's missing value is the same as their last measured value. However, LOCF may not be appropriate if the variable is subject to change over time.\n",
    "\n",
    "4. **Linear Interpolation**: This method estimates the missing values by fitting a straight line between the nearest observed values before and after the missing data point. Linear interpolation can introduce bias if the underlying pattern is not linear.\n",
    "\n",
    "5. **Multiple Imputation**: Multiple imputation generates multiple plausible imputed datasets based on the observed data's uncertainty. Statistical analyses are performed on each imputed dataset, and the results are pooled to provide unbiased estimates and valid standard errors. This method accounts for the uncertainty associated with the missing data, making it a robust approach when assumptions about the missing data mechanism are unclear.\n",
    "\n",
    "6. **Maximum Likelihood Estimation (MLE)**: MLE is an advanced statistical technique that estimates the model parameters by maximizing the likelihood function, accounting for the missing data mechanism. MLE is often considered more sophisticated and robust than simple imputation methods, but it requires more complex modeling and may be computationally intensive.\n",
    "\n",
    "The potential consequences of using different methods to handle missing data can vary:\n",
    "\n",
    "- Complete case analysis may result in biased estimates and reduced statistical power due to the loss of information.\n",
    "- Mean imputation can lead to underestimation of variability and biased results.\n",
    "- LOCF may introduce systematic errors if the variable is not stable over time.\n",
    "- Linear interpolation may provide inaccurate estimates if the underlying pattern is not linear.\n",
    "- Multiple imputation and MLE are generally more robust and provide valid estimates if assumptions about the missing data mechanism are appropriate.\n",
    "\n",
    "Choosing the most appropriate method for handling missing data depends on the nature of the data, the extent of missingness, and the assumptions about the missing data mechanism. It is essential to carefully consider the potential consequences of each method and perform sensitivity analyses to assess the robustness of the results to different missing data approaches. Additionally, researchers should report the method used for handling missing data and acknowledge its potential impact on the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d661c75-3d6c-4015-9427-3e2e2df4c468",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary.\n",
    "\n",
    "\n",
    "Answer(Q8):\n",
    "\n",
    "After obtaining significant results from ANOVA, post-hoc tests are used to identify specific pairwise differences between group means. These tests help determine which groups are significantly different from each other when there are three or more groups being compared. Some common post-hoc tests are:\n",
    "\n",
    "1. **Tukey's Honestly Significant Difference (HSD)**: Tukey's HSD test is conservative and controls the family-wise error rate, making it appropriate when you have equal sample sizes and are interested in all pairwise comparisons between groups. It is often used when the number of groups is relatively small.\n",
    "\n",
    "2. **Bonferroni Correction**: The Bonferroni correction divides the significance level (alpha) by the number of comparisons being made to maintain a family-wise error rate. It is suitable when you have a large number of pairwise comparisons but can be quite conservative.\n",
    "\n",
    "3. **Scheffe's Test**: Scheffe's test is less conservative than Bonferroni and can be used when you have unequal sample sizes or are interested in complex comparisons between groups.\n",
    "\n",
    "4. **Dunnett's Test**: Dunnett's test is used when you have a control group and want to compare all other groups to the control group, controlling for the family-wise error rate.\n",
    "\n",
    "5. **Games-Howell Test**: The Games-Howell test is used when the assumption of equal variances is violated. It is a more appropriate choice than Tukey's HSD when the groups have unequal variances.\n",
    "\n",
    "Example situation:\n",
    "\n",
    "Suppose a researcher conducts an experiment to compare the effectiveness of three different treatments (A, B, and C) in reducing anxiety levels. The dependent variable is the anxiety score, and there are 50 participants in each treatment group. After performing a one-way ANOVA, the researcher finds a significant difference in anxiety levels among the three treatments (p < 0.05).\n",
    "\n",
    "Now, to determine which treatments differ significantly from each other, the researcher can conduct post-hoc tests. Let's say the researcher decides to use Tukey's HSD test. The results of the Tukey post-hoc test might show that treatment A and B have no significant difference in anxiety levels (p > 0.05), treatment B and C have no significant difference (p > 0.05), but treatment A and C show a significant difference (p < 0.05).\n",
    "\n",
    "Based on this post-hoc test, the researcher can conclude that treatment A and C have significantly different effects on anxiety levels, while treatment B does not differ significantly from either of them. The post-hoc test helps the researcher identify the specific pairwise differences between the treatments and provides a more nuanced understanding of the results obtained from the initial ANOVA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1312a36f-2f5c-4cf6-840a-095c698cc22e",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results.\n",
    "\n",
    "Answer(Q9):\n",
    "\n",
    "To conduct a one-way ANOVA in Python and determine if there are significant differences between the mean weight loss of the three diets (A, B, and C), we can use the `scipy.stats` module. Make sure you have the necessary libraries installed before running the code. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3adfd58-b199-4eaf-b5e2-4f535ef83f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 43.628411103115354\n",
      "p-value: 1.3348851612096758e-15\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Sample data (replace these with your actual data)\n",
    "diet_A = np.array([3.2, 4.5, 5.1, 4.9, 3.8, 5.3, 4.7, 5.2, 4.0, 4.6,\n",
    "                   3.9, 4.2, 4.8, 5.0, 5.4, 3.6, 4.1, 4.3, 4.4, 4.0,\n",
    "                   3.7, 5.1, 5.3, 3.5, 4.8, 4.2, 5.1, 4.5, 4.0, 4.9,\n",
    "                   4.5, 4.3, 4.8, 3.9, 5.0, 3.6, 5.2, 4.6, 4.3, 5.1,\n",
    "                   5.0, 4.2, 4.7, 4.4, 4.5, 3.8, 4.6, 4.2, 4.9, 4.0])\n",
    "\n",
    "diet_B = np.array([3.1, 3.8, 4.2, 3.9, 4.3, 4.0, 4.5, 3.7, 4.0, 4.2,\n",
    "                   4.1, 4.4, 3.5, 3.9, 3.8, 4.3, 4.2, 4.0, 4.1, 3.6,\n",
    "                   4.1, 3.9, 4.0, 4.4, 4.2, 3.7, 4.1, 4.5, 4.3, 4.0,\n",
    "                   4.2, 4.6, 3.8, 4.5, 4.1, 3.7, 4.0, 3.9, 3.6, 4.3,\n",
    "                   4.2, 4.1, 4.4, 3.9, 4.3, 3.5, 4.1, 4.0, 4.2, 3.8])\n",
    "\n",
    "diet_C = np.array([4.0, 5.1, 4.9, 4.7, 4.3, 4.6, 5.3, 5.0, 4.5, 4.9,\n",
    "                   4.1, 4.2, 4.6, 4.7, 5.2, 4.3, 5.0, 4.8, 4.9, 4.5,\n",
    "                   5.1, 5.4, 5.3, 4.8, 4.9, 5.2, 4.6, 4.4, 5.0, 4.7,\n",
    "                   4.3, 5.1, 5.3, 4.9, 5.0, 5.2, 4.5, 5.1, 4.6, 5.0,\n",
    "                   4.9, 4.7, 4.8, 5.4, 4.3, 4.5, 5.0, 4.8, 4.7, 5.1])\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Print the results\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7be42fd-4698-4c44-b606-e63a58b54c40",
   "metadata": {},
   "source": [
    "In this code, we have three arrays representing the weight loss data for diets A, B, and C. We then use the f_oneway function from scipy.stats to perform the one-way ANOVA on the data.\n",
    "\n",
    "Assuming you run this code, you will get the F-statistic and p-value as the output. The F-statistic represents the variation between the group means relative to the variation within the groups. The p-value represents the probability of observing the obtained results (or more extreme results) if there were no true differences between the group means.\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "If the p-value is less than the chosen significance level (e.g., 0.05), you can conclude that there are significant differences between at least some of the diets' mean weight loss. This would indicate that the diets have different effects on weight loss in the sample of participants.\n",
    "\n",
    "If the p-value is greater than the chosen significance level, you would not have enough evidence to claim that there are significant differences between the diets' mean weight loss. In this case, you would fail to reject the null hypothesis, which suggests that there are no significant differences among the diets in terms of weight loss in the sample.\n",
    "\n",
    "Remember that the interpretation should consider both statistical significance (p-value) and practical significance (effect size) to draw meaningful conclusions from the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2312a991-66f0-4ea8-8cd1-410e123dfbf7",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results.\n",
    "\n",
    "Answer(Q10):\n",
    "\n",
    "To conduct a two-way ANOVA in Python and determine if there are any main effects or interaction effects between the software programs and employee experience level, you can use the `statsmodels` library. Make sure you have the necessary libraries installed before running the code. Here's how you can do it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c562ed00-7696-429a-a7f9-ddaaf546c9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data[Time].count =  50\n",
      "data[Program].count =  50\n",
      "data[Experience].count =  50\n",
      "                              sum_sq    df         F    PR(>F)\n",
      "C(Program)                 98.343418   2.0  3.231081  0.049058\n",
      "C(Experience)              20.031390   1.0  1.316266  0.257464\n",
      "C(Program):C(Experience)   16.635977   2.0  0.546576  0.582808\n",
      "Residual                  669.607143  44.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data (replace these with your actual data)\n",
    "data = {\n",
    "    'Time': [25, 30, 28, 32, 29, 27, 30, 35, 26, 31, 30, 33, 28, 27, 32, 34, 29, 31, 28, 33, \n",
    "             22, 24, 20, 25, 23, 26, 28, 27, 25, 29, 21, 20, 22, 26, 23, 25, 21, 24, 23, 22, \n",
    "             28, 32, 31, 30, 29, 33, 34, 32, 31, 30],\n",
    "    'Program': ['A', 'A', 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'B', 'B', 'C', 'C', 'C', 'C', 'C', \n",
    "                'C', 'A', 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'B', 'B', 'C', 'C', 'C', 'C', 'C', \n",
    "                'C', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'B', 'B', 'C', 'C', 'C'],\n",
    "    'Experience': ['Novice', 'Novice', 'Novice', 'Experienced', 'Experienced', 'Experienced',\n",
    "                   'Novice', 'Novice', 'Novice', 'Experienced', 'Experienced', 'Experienced',\n",
    "                   'Novice', 'Novice', 'Novice', 'Experienced', 'Experienced', 'Experienced',\n",
    "                   'Novice', 'Novice', 'Novice', 'Experienced', 'Experienced', 'Experienced',\n",
    "                   'Novice', 'Novice', 'Novice', 'Experienced', 'Experienced', 'Experienced',\n",
    "                   'Novice', 'Novice', 'Novice', 'Experienced', 'Experienced', 'Experienced',\n",
    "                   'Novice', 'Novice', 'Novice', 'Experienced', 'Experienced', 'Experienced',\n",
    "                   'Novice', 'Novice', 'Novice', 'Experienced', 'Experienced', 'Experienced','Novice', 'Novice']\n",
    "}\n",
    "\n",
    "print('data[Time].count = ',len(data['Time']))\n",
    "print('data[Program].count = ',len(data['Program']))\n",
    "print('data[Experience].count = ',len(data['Experience']))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Time ~ C(Program) + C(Experience) + C(Program):C(Experience)', data=df).fit()\n",
    "\n",
    "# Get the ANOVA table\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857451ea-9403-4b66-89e6-f7b565114fcf",
   "metadata": {},
   "source": [
    "In this code, we have three arrays representing the time taken to complete the task, the software program used, and the experience level of the employees. We then use the `ols` function from `statsmodels.formula.api` to fit the two-way ANOVA model, including the main effects of `Program` and `Experience`, as well as their interaction effect `Program:Experience`.\n",
    "\n",
    "Assuming you run this code, you will get the F-statistics and p-values for each main effect and the interaction effect as the output. The ANOVA table contains the sum of squares, degrees of freedom, F-statistics, and p-values for each effect.\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "- If the p-value for the main effect of `Program` is less than the chosen significance level (e.g., 0.05), you can conclude that there is a significant main effect of the software programs on the time it takes to complete the task. This would indicate that at least one software program has a different effect on task completion time compared to the others.\n",
    "\n",
    "- If the p-value for the main effect of `Experience` is less than the significance level, you can conclude that there is a significant main effect of employee experience level on task completion time. This suggests that the experience level of the employees affects the time it takes to complete the task.\n",
    "\n",
    "- If the p-value for the interaction effect `Program:Experience` is less than the significance level, you can conclude that there is a significant interaction effect between the software programs and employee experience level. This indicates that the effect of the software programs on task completion time varies depending on the employees' experience level.\n",
    "\n",
    "Remember that interpreting the results of a two-way ANOVA should involve considering both statistical significance (p-values) and practical significance (effect size) to draw meaningful conclusions from the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e169e243-3d9f-4334-b07f-14a06be8d7a6",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other.\n",
    "\n",
    "Answer(Q11):\n",
    "\n",
    "To conduct a two-sample t-test in Python to determine if there are significant differences in test scores between the control group (traditional teaching method) and the experimental group (new teaching method), you can use the scipy.stats module. Additionally, if the t-test results are significant, you can follow up with a post-hoc test to identify which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e83b7a6f-2943-4e4f-a47e-795001b92156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-sample t-test:\n",
      "t-statistic: -17.342139410189265\n",
      "p-value: 1.809207314697429e-43\n",
      "The results of the two-sample t-test are significant. There is a significant difference in test scores between the control group and the experimental group.\n",
      "  Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "========================================================\n",
      " group1    group2    meandiff p-adj lower  upper  reject\n",
      "--------------------------------------------------------\n",
      "Control Experimental   5.7372   0.0 5.0853 6.3891   True\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Sample data \n",
    "control_group_scores = np.array([80, 75, 85, 72, 78, 82, 76, 81, 77, 79, 75, 83, 79, 80, 76, 78, 82, 81, 78, 80,\n",
    "                                 77, 79, 81, 76, 80, 85, 74, 77, 78, 81, 76, 79, 83, 77, 81, 79, 80, 82, 78,\n",
    "                                 80, 76, 75, 82, 79, 81, 78, 80, 76, 82, 79, 77, 80, 75, 84, 80, 82, 78, 80,\n",
    "                                 76, 80, 78, 82, 81, 78, 75, 80, 79, 76, 81, 82, 78, 79, 80, 82, 75, 78, 80,\n",
    "                                 82, 80, 75, 77, 81, 76, 78, 83, 80, 75, 79, 82, 80, 77, 78, 80, 76, 82, 79,\n",
    "                                 80, 83, 78, 76, 80, 81, 79, 80, 82, 78, 75, 80, 79, 81, 76, 82, 79, 77, 80])\n",
    "\n",
    "experimental_group_scores = np.array([85, 82, 89, 80, 84, 87, 82, 88, 81, 83, 86, 89, 80, 82, 85, 86, 83, 88, 84, 85,\n",
    "                                      81, 87, 86, 83, 82, 89, 82, 86, 85, 87, 83, 88, 85, 82, 84, 87, 83, 88, 82,\n",
    "                                      86, 83, 82, 87, 80, 84, 89, 82, 86, 83, 88, 81, 85, 82, 86, 87, 83, 89, 82,\n",
    "                                      88, 85, 82, 84, 87, 83, 89, 82, 86, 83, 85, 87, 82, 86, 85, 88, 83, 87, 82,\n",
    "                                      89, 85, 83, 86, 82, 88, 84, 85, 83, 86, 88, 82, 87, 85, 89, 83, 84, 86, 82,\n",
    "                                      88, 81, 83, 86, 85, 87, 82, 89, 85, 82, 86, 83, 88, 84, 85, 83, 86, 87])\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = ttest_ind(control_group_scores, experimental_group_scores)\n",
    "\n",
    "# Print the t-test results\n",
    "print(\"Two-sample t-test:\")\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Check if the results are significant\n",
    "if p_value < 0.05:\n",
    "    print(\"The results of the two-sample t-test are significant. There is a significant difference in test scores \"\n",
    "          \"between the control group and the experimental group.\")\n",
    "    \n",
    "    # Perform post-hoc test (Tukey's HSD) to identify significant group differences\n",
    "    all_scores = np.concatenate([control_group_scores, experimental_group_scores])\n",
    "    group_labels = ['Control'] * len(control_group_scores) + ['Experimental'] * len(experimental_group_scores)\n",
    "    posthoc = pairwise_tukeyhsd(all_scores, group_labels)\n",
    "    print(posthoc)\n",
    "else:\n",
    "    print(\"The results of the two-sample t-test are not significant. There is no significant difference in test \"\n",
    "          \"scores between the control group and the experimental group.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53de8d43-a5cd-4f95-9edb-04e693f8ee29",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a posthoc test to determine which store(s) differ significantly from each other.\n",
    "\n",
    "Answer(Q12):\n",
    "\n",
    "\n",
    "A repeated measures ANOVA is used when the same participants are measured under different conditions or at multiple time points. In this scenario, we have data from the same stores (Store A, Store B, and Store C) over 30 days, which could be considered a within-subjects design. However, the repeated measures ANOVA is typically used with multiple measurements on the same subject, rather than multiple measurements on different subjects (stores). In this case, it's more appropriate to use a one-way ANOVA to compare the average daily sales between the three stores.\n",
    "\n",
    "Here's how we can conduct a one-way ANOVA in Python to determine if there are significant differences in average daily sales between the three stores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d77619c3-6f33-4113-ac13-e684becb334b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-way ANOVA:\n",
      "F-statistic: 236.66651174069443\n",
      "p-value: 6.481521729491659e-36\n",
      "The results of the one-way ANOVA are significant. There are significant differences in daily sales between the three stores.\n",
      "  Multiple Comparison of Means - Tukey HSD, FWER=0.05  \n",
      "=======================================================\n",
      " group1  group2 meandiff p-adj  lower    upper   reject\n",
      "-------------------------------------------------------\n",
      "Store A Store B -14.0333   0.0 -16.7142 -11.3525   True\n",
      "Store A Store C -24.3667   0.0 -27.0475 -21.6858   True\n",
      "Store B Store C -10.3333   0.0 -13.0142  -7.6525   True\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Sample data (replace these with your actual data)\n",
    "store_A_sales = np.array([100, 110, 105, 98, 120, 115, 102, 107, 112, 108,\n",
    "                          99, 105, 104, 112, 114, 116, 100, 110, 105, 98,\n",
    "                          120, 115, 102, 107, 112, 108, 99, 105, 104, 112])\n",
    "\n",
    "store_B_sales = np.array([90, 95, 88, 94, 92, 96, 93, 98, 89, 94,\n",
    "                          92, 96, 93, 98, 89, 94, 92, 96, 93, 98,\n",
    "                          89, 94, 92, 96, 93, 98, 89, 94, 92, 96])\n",
    "\n",
    "store_C_sales = np.array([80, 85, 82, 79, 83, 81, 84, 88, 85, 82,\n",
    "                          79, 83, 81, 84, 88, 85, 82, 79, 83, 81,\n",
    "                          84, 88, 85, 82, 79, 83, 81, 84, 88, 85])\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = f_oneway(store_A_sales, store_B_sales, store_C_sales)\n",
    "\n",
    "# Print the ANOVA results\n",
    "print(\"One-way ANOVA:\")\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Check if the results are significant\n",
    "if p_value < 0.05:\n",
    "    print(\"The results of the one-way ANOVA are significant. There are significant differences in daily sales \"\n",
    "          \"between the three stores.\")\n",
    "\n",
    "    # Perform post-hoc test (e.g., Tukey's HSD) to identify significant store differences\n",
    "    all_sales = np.concatenate([store_A_sales, store_B_sales, store_C_sales])\n",
    "    group_labels = ['Store A'] * len(store_A_sales) + ['Store B'] * len(store_B_sales) + ['Store C'] * len(store_C_sales)\n",
    "    # Replace 'method' parameter with 'bonferroni' or 'hsd' for different post-hoc tests\n",
    "    posthoc = pairwise_tukeyhsd(all_sales, group_labels, alpha=0.05)\n",
    "    print(posthoc)\n",
    "else:\n",
    "    print(\"The results of the one-way ANOVA are not significant. There are no significant differences in daily sales \"\n",
    "          \"between the three stores.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d0b3a4-4f0b-48c1-a26f-914b79631d56",
   "metadata": {},
   "source": [
    "In this code, we first perform a one-way ANOVA using the f_oneway function from scipy.stats to compare the average daily sales between the three stores. If the p-value is less than 0.05, we conclude that there are significant differences in daily sales between the stores. Then, we can perform a post-hoc test (in this case, Tukey's Honestly Significant Difference test) to identify which stores differ significantly from each other.\n",
    "\n",
    "We can use other post-hoc tests, such as Bonferroni correction or Dunn's test, depending on the specific requirements of your analysis. Also, remember to replace the sample data with your actual data for a more meaningful analysis.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
